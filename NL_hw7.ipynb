{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "NL_hw7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpJA0ninYLc5"
      },
      "source": [
        "## Домашняя работа №7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5OJhir-YLc7"
      },
      "source": [
        "Запустить seq2seq, seq2seq с внимаием для перевода русских слов + описать наблюдения по качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8HsoZtGYLc8"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obOps_C1YLdG"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "latent_dim = 256\n",
        "num_samples = 10000\n",
        "data_path = 'rus.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a62z1kLIYLdP"
      },
      "source": [
        "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zpOOphBYLdY"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zef3c4WoYLdc"
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xik8nx1YLdh"
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
        "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
        "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlgQAKWrYLdl",
        "outputId": "72dbed4c-b1e6-4887-895f-dc13f0b5400a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 2s 17ms/step - loss: 1.1329 - accuracy: 0.7725 - val_loss: 0.9068 - val_accuracy: 0.7588\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.7251 - accuracy: 0.8058 - val_loss: 0.7655 - val_accuracy: 0.7988\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.7083 - accuracy: 0.8163 - val_loss: 0.7270 - val_accuracy: 0.8067\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.6051 - accuracy: 0.8360 - val_loss: 0.6715 - val_accuracy: 0.8142\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.5606 - accuracy: 0.8431 - val_loss: 0.6330 - val_accuracy: 0.8210\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.5328 - accuracy: 0.8488 - val_loss: 0.6102 - val_accuracy: 0.8260\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.5136 - accuracy: 0.8533 - val_loss: 0.5920 - val_accuracy: 0.8314\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4981 - accuracy: 0.8571 - val_loss: 0.5755 - val_accuracy: 0.8347\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4833 - accuracy: 0.8607 - val_loss: 0.5636 - val_accuracy: 0.8369\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4712 - accuracy: 0.8633 - val_loss: 0.5524 - val_accuracy: 0.8395\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4608 - accuracy: 0.8657 - val_loss: 0.5394 - val_accuracy: 0.8445\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4496 - accuracy: 0.8684 - val_loss: 0.5305 - val_accuracy: 0.8450\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4400 - accuracy: 0.8711 - val_loss: 0.5194 - val_accuracy: 0.8483\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4307 - accuracy: 0.8737 - val_loss: 0.5115 - val_accuracy: 0.8499\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4213 - accuracy: 0.8766 - val_loss: 0.5052 - val_accuracy: 0.8527\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4118 - accuracy: 0.8792 - val_loss: 0.4976 - val_accuracy: 0.8550\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.4030 - accuracy: 0.8821 - val_loss: 0.4907 - val_accuracy: 0.8558\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3949 - accuracy: 0.8846 - val_loss: 0.4834 - val_accuracy: 0.8593\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3873 - accuracy: 0.8867 - val_loss: 0.4764 - val_accuracy: 0.8617\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3795 - accuracy: 0.8892 - val_loss: 0.4725 - val_accuracy: 0.8633\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3708 - accuracy: 0.8919 - val_loss: 0.4677 - val_accuracy: 0.8644\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3642 - accuracy: 0.8939 - val_loss: 0.4605 - val_accuracy: 0.8667\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3565 - accuracy: 0.8958 - val_loss: 0.4568 - val_accuracy: 0.8682\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3494 - accuracy: 0.8979 - val_loss: 0.4515 - val_accuracy: 0.8708\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3418 - accuracy: 0.9000 - val_loss: 0.4478 - val_accuracy: 0.8708\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3347 - accuracy: 0.9021 - val_loss: 0.4420 - val_accuracy: 0.8722\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3272 - accuracy: 0.9046 - val_loss: 0.4403 - val_accuracy: 0.8723\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3197 - accuracy: 0.9066 - val_loss: 0.4376 - val_accuracy: 0.8752\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.3125 - accuracy: 0.9088 - val_loss: 0.4340 - val_accuracy: 0.8764\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3059 - accuracy: 0.9105 - val_loss: 0.4331 - val_accuracy: 0.8766\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2983 - accuracy: 0.9127 - val_loss: 0.4317 - val_accuracy: 0.8770\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2922 - accuracy: 0.9142 - val_loss: 0.4297 - val_accuracy: 0.8775\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2844 - accuracy: 0.9167 - val_loss: 0.4280 - val_accuracy: 0.8787\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2779 - accuracy: 0.9183 - val_loss: 0.4228 - val_accuracy: 0.8805\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2707 - accuracy: 0.9203 - val_loss: 0.4222 - val_accuracy: 0.8802\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2648 - accuracy: 0.9219 - val_loss: 0.4231 - val_accuracy: 0.8807\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2571 - accuracy: 0.9243 - val_loss: 0.4199 - val_accuracy: 0.8822\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2503 - accuracy: 0.9263 - val_loss: 0.4210 - val_accuracy: 0.8824\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2437 - accuracy: 0.9283 - val_loss: 0.4204 - val_accuracy: 0.8832\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2374 - accuracy: 0.9300 - val_loss: 0.4217 - val_accuracy: 0.8833\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2313 - accuracy: 0.9318 - val_loss: 0.4222 - val_accuracy: 0.8830\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2250 - accuracy: 0.9332 - val_loss: 0.4237 - val_accuracy: 0.8838\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2190 - accuracy: 0.9352 - val_loss: 0.4243 - val_accuracy: 0.8844\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2146 - accuracy: 0.9367 - val_loss: 0.4241 - val_accuracy: 0.8846\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2077 - accuracy: 0.9384 - val_loss: 0.4275 - val_accuracy: 0.8842\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.2004 - accuracy: 0.9407 - val_loss: 0.4313 - val_accuracy: 0.8846\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1943 - accuracy: 0.9423 - val_loss: 0.4361 - val_accuracy: 0.8841\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1890 - accuracy: 0.9438 - val_loss: 0.4350 - val_accuracy: 0.8847\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1841 - accuracy: 0.9453 - val_loss: 0.4365 - val_accuracy: 0.8851\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 0.1788 - accuracy: 0.9469 - val_loss: 0.4375 - val_accuracy: 0.8859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f098e3eb8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRa1lGNjYLdr",
        "outputId": "49b6d4d2-905d-46c6-ed5f-3b2548ca3d9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "for seq_index in np.random.choice(range(100), 15, replace=False):\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sentence: Go now.\n",
            "Decoded sentence: Иди дылай.\n",
            "\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Идите.\n",
            "\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыборись!\n",
            "\n",
            "Input sentence: Freeze!\n",
            "Decoded sentence: Ни комас!\n",
            "\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Вот это!\n",
            "\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Беги!\n",
            "\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Вот это!\n",
            "\n",
            "Input sentence: Smile.\n",
            "Decoded sentence: Улыборись!\n",
            "\n",
            "Input sentence: Got it!\n",
            "Decoded sentence: Усёр!\n",
            "\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Вот это!\n",
            "\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Помогите!\n",
            "\n",
            "Input sentence: Got it?\n",
            "Decoded sentence: Исёт сто!\n",
            "\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: Привет!\n",
            "\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Посторо!\n",
            "\n",
            "Input sentence: Shoot!\n",
            "Decoded sentence: Покажите!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9xpMpdVYLdv"
      },
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "data_path = 'rus.txt'\n",
        "num_samples = 10000\n",
        "\n",
        "#tf.enable_eager_execution()\n",
        "\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zа-яA-ZА-Я?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().split('\\n')\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split('\\t')\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(preprocess_sentence(input_text))\n",
        "    target_texts.append(preprocess_sentence(target_text))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKyPnA_4YLdz"
      },
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOp_jg7YLd3"
      },
      "source": [
        "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
        "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbZg-rZiYLd-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_tensor_train, input_tensor_val, \\\n",
        " target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D0-gV74YLeF"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
        "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmpS_lHFYLeK"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.lstm(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "    \n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.lstm(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqS3rFlcYLeO"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kocTlJhFYLeS"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpAryc0wYLeV",
        "outputId": "39599ac6-caf5-4ac8-a020-9288354cea74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.6306\n",
            "Epoch 2 Loss 1.2397\n",
            "Epoch 3 Loss 1.0736\n",
            "Epoch 4 Loss 0.9406\n",
            "Epoch 5 Loss 0.8072\n",
            "Epoch 6 Loss 0.6926\n",
            "Epoch 7 Loss 0.5890\n",
            "Epoch 8 Loss 0.4931\n",
            "Epoch 9 Loss 0.4128\n",
            "Epoch 10 Loss 0.3422\n",
            "Epoch 11 Loss 0.2877\n",
            "Epoch 12 Loss 0.2482\n",
            "Epoch 13 Loss 0.2192\n",
            "Epoch 14 Loss 0.2015\n",
            "Epoch 15 Loss 0.1865\n",
            "Epoch 16 Loss 0.1731\n",
            "Epoch 17 Loss 0.1672\n",
            "Epoch 18 Loss 0.1581\n",
            "Epoch 19 Loss 0.1546\n",
            "Epoch 20 Loss 0.1494\n",
            "Epoch 21 Loss 0.1460\n",
            "Epoch 22 Loss 0.1421\n",
            "Epoch 23 Loss 0.1400\n",
            "Epoch 24 Loss 0.1363\n",
            "Epoch 25 Loss 0.1356\n",
            "Epoch 26 Loss 0.1328\n",
            "Epoch 27 Loss 0.1301\n",
            "Epoch 28 Loss 0.1284\n",
            "Epoch 29 Loss 0.1280\n",
            "Epoch 30 Loss 0.1269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyqVBYWrYLeZ"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence, attention_plot\n",
        "\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    fontdict = {'fontsize': 14}\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    plt.show()\n",
        "    \n",
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6F39eCRYLeg",
        "outputId": "640eba10-f44b-49ec-b601-65dbe469e0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "translate(u'good morning!')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> good morning ! <end>\n",
            "Predicted translation: ну и бардак ! <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAJyCAYAAABDmSO9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debzt93zv8fcniSSSGCohQRExDzUeY0pTtFpVdVttDTFXVIu2qu1FS3C1aFClLVEUUaWKcN0HNbSGtEWoEkJMEUEqUVPmI/ncP9Y6sm3nJOd7zj77d9baz+fjsR9n799v7b0/e+Vkndf+jdXdAQDYXntMPQAAsFjEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAk6uqi6vqom28nVNV/1VVj596TmBmr6kHAEjy2CRHJ3lzkg/Nl90hyX2TPCfJtZI8u6q6u180yYTAD5QbYy2uqrpBkpcm+Z3u/uTU88COqqrjk7y1u1++avkjk9ynu3+pqn4zyeO6+2aTDAn8gN0Wi+2hSY5I8oiJ54Cddfck79vK8vclucf8/Xclue66TQRsk3hYUFVVSR6c5BVJHlhVe048EuyMb2a2i2K1+yY5a/7+AUm+s24TAdvkmIfFdUSSKyR5fJKfT3KvJG+bciDYCU9P8rKquluSD8+X3S7JzyZ51Pzjn8nWt04A68wxDwuqqv4uyYXdfVRVPS/Jdbr7fhOPBTusqu6U5HFJbjxf9Jkkf9nd/zHdVMDWiIcFVFX7J/l6kl/o7g9U1a2S/HuSq3f3t6edDoBlZ7fFYvqVJGd19weSpLs/XlWfS3L/JC+ZdDLYCVV1jSRXy6rjsbr7Y9NMBDtn/sveryQ5vruX5pgdB0wupgcnOW7VsuOSPGz9R4GdV1W3rqpPJflKko8lOXHF20emnA120q8leWVmr9tLw26LBVNV10rypSQ36e7PrVj+40lOTXLT7j5lovFgh1TVRzI74+IZSb6W5IdemLr7y1PMBTurqv4lycFJzu3uTVPPs1bEAzC5qjonya2FL8ukqg5NckqS2yf5jyS36e5PTznTWrHbYgFV1bXn13nY6rr1ngfWwCeTHDL1ELDGHpzkA9398ST/L7ML+y0F8bCYvpTkqqsXVtWB83WwaJ6c5LlVdY+qOriqrrLyberhYAc9JMlr5u+/NsmDtvWL36Kx22IBVdXFSQ7u7jNXLb9Okk939/7TTAY7Zv53eouVL0qVpLvbFVRZKFV15yT/nOSQ7j67qvZOckaSX+/ud0073c5zquYCqaq/nL/bSf6sqs5dsXrPzParfXzdB4Od99NTDwBr7KGZnZ55dpJ094VV9YbMzooTD6yrn5j/WUlukuTCFesuzOwUt2PWeyjYWd3tstMsjaraJ7NTNB+watVxSd5ZVQdsiYpFZbfFgpnvL3tDkkd09/emngd2VFXdJsnHu/vi+fvb5CJRLJKqOiiz+w0d190Xr1p3ZJJ3d/cZkwy3RsTDgpnfPfP8JLdcllN+2Jjmxzkc0t3fmL/fmW1VW80xD7CbsdtiwXT3RVX15SR7Tz0L7KTrJjlzxfvAgrDlYQFV1UMz25d2ZHefNfU8ACRV9aWsujrqtnT3Ybt4nF3KlofF9MTMflP7alWdnuSclSu7+xaTTAU7oar2S3KrbP3GWG+aZCgY8+IV7x+Q5AlJPpzZXY+T5E6ZnRX3vHWea82Jh8X0xqkHWFZV9dTtfWx3P2NXzrKRVNU9krwuyYFbWd2ZnYoMu7Xu/kEUVNXfJXlOd//pysdU1ZOS3GydR1tzdlvAClX1yVWLrpNkv8xu1pQk10hybpJTbeFZO/M7an4kyZO7+2uX9XjY3VXVdzO7l8XnVy2/fpKPdfcVp5lsbdjyACt095ZraaSqHp7Z5WUf2t2nzZddO7Pb6752mgmX1qFJ7iMcWCLnJDkiyedXLT8is19AFpp4WEDzy5w+JbODJq+d5HIr1zutbc08Ncl9t4RDknT3aVX1+0mOT/KKySZbPickuVGSL0w9CKyRFyT5q6ralNkdNZPkjpldefLoqYZaK+JhMT0zya8n+bPM/oL+QWa/ud0/yZ9MN9bSOTjJ5beyfN8kB63zLMvuJUmOqaprZHaHzc0rV7pIFIumu59bVacm+Z3MrjaZJCdntiXzDZMNtkYc87CA5qcDPaa731FV30tyq+7+QlU9Jsndu/t+E4+4FKrq+CSHJXlUZvvjO7MjpV+a5Evdfd8Jx1sqq26MtZqLRMFuxpaHxXRwki1Xlzw7yZXn778jyXMmmWg5/UaSVyX5tyQXzZftkeSdmQUFa8dFolhaVXXl/Ojpx/8z0ThrQjwsptMyO+r/tMwOxrlnko9mdg7xeRPOtVTmtzy/V1XdMMmN54s/092nTDjW0qmqyyX5UGZbzT419TywFqrqOpntjjsiP3xF4MoSnH4sHhbTm5PcPbODcF6Y5HVV9agk10zy51MOtoy6+5Sq+trs3T7nMj+BId29uao2ZzuvzAcL4pWZbRV+ZGanei/V32/HPCyBqrpDksOTnNLd/3fqeZZJVf12kj/KLMyS5PTMLvzy19NNtXyq6g8zu+X8w7v7+1PPAzurqs5OcsfuPmnqWXYFWx4WUFXdNcm/bXmR7e4PJflQVe1VVXft7vdPO+FyqKonJ3lSkmOSfHC++C5Jnl1VV+zuZ0823PK5S5KfyuyS6yflRy+5fp9JpoId96Uk+0w9xK5iy8MCqqqLkly9u7+xavmBSb7hyPS1UVWnJfmj7n7dquUPSvKn3X2daSZbPlX1yktb390PX69ZYC1U1d2S/O8kv7X6KpPLQDwsoPlpbQfPD+hbufyGSU5c9Mue7i6q6vwkN9/K5WVvkOST3b3vNJMBu7v5afT7ZHZg5AVJfmh33KK/TtttsUCq6q3zdzvJcVV1wYrVeya5eWanFbI2TknywCSrb4D1wCSfXf9xll9VHZbkppn9HT+5u7848Uiwox479QC7knhYLN+c/1lJvpUfPi3zwsz2y79svYdaYkcnecP8GJMT5ssOz2zf/K9ONdQyqqorJnl5kl9JcvEli+ufkjyyu7832XCwA7r7VVPPsCvZbbGAquppSY5x2uCuV1W3TfJ7SW4yX3Rykud1939ON9XymR/zcOckR+WSrWeHZ3ae/And/cipZoMdVVUHJ3lwkusl+ZPuPquqDk/yte7+0rTT7RzxsICqao8k6e6L5x8fkuTeST7d3XZbsHCq6puZ3YTsA6uW3zXJm7v7wGkmgx0z/8XjPZmddXGzJDfu7i9W1dFJbtjdD5xyvp1lt8Vientml6J+YVUdkOTEJPsnOaCqHtndr550uiVSVfskeVAu2Q//qSSv6+4LLvUTGXX5XLJbbqX/yexGZLBojknywu5+2vzgyS3emWThzx7a47Ifwm5oU5L3zt//5STfTXK1zO638MSphlo2VXXTJJ9L8vwkd8jsdrp/keSUqrrJpX0uw05I8syq2m/LgqraP8nT4yBgFtNtM7s3zmpfz+z+RAvNlofFdECSb8/f/9nMNuturqr3Jvmr6cZaOi9M8p9JHtzd301+cGDfcZlFxD0nnG3Z/F5mv5F9tao+MV/2E5kdFPyzk00FO+68JD+2leU3TvKNrSxfKOJhMZ2W5PCqeltm/4BtOfL/KknOnWyq5XN4ktttCYck6e7vVtVTMruvCGuku0+aXz/jgbnk4NTXJHltd7vZG4vo+CRPq6otr89dVYdmdufjf5pqqLVit8Vien5mL6ynJ/lqki2Xo75rkk9ONdQSOj+X3O58pSvN17G2rpDZMQ6fS/KFzO5E+PCq+q1Jp4Id88TMfqE7M8l+mZ1K//kk30nyxxPOtSacbbGg5kfyXjvJu7r77PmyX0jy7e4+4VI/me1SVa9KcrvMjiXZsqXhTklemuTDLpm8dqrqyCR/m0uuYbLyham7+xqTDAY7aX6Z6ttk9sv6x7r73ROPtCbEw4KpqislucXqU9rm6w7P7HTNb63/ZMunqq6c2QFPv5jkovniPTPbHPnw7v72tj6XMVX15cye62e4qyaLbiO8TouHBVNVV8jsaN17rtzCUFW3TPLhJNfs7rOmmm8ZVdX1s+IiUct4k5upVdW3ktzW5ahZBhvhdVo8LKCqem2Ss7v70SuWHZPZhUfcuniNVNUrtrGqMzvm4fNJXt/dX1u/qZZTVb04yWe7+0VTzwJrYdlfp8XDAqqqeyZ5XZJDuvvC+RUnT0/y2O5+07TTLY/52Sx3yexeCyfNF988s/3yH83sqnEHJLlLd398kiGXRFXtneQtmd2j5ZNJNq9c392rb04Gu7Vlf512quZieldm5xDfO8mbktw9syPT3zblUEvohCRnZ3ZjpnOTZH4Ro5cl+a8k90ry6iTPy+y/ATvu0Ul+LslZSa6fVQdM5kfvbAq7u6V+nbblYUFV1XOS3Ki771tVr07yve7+7annWiZV9fUkd+vuk1ctv2mS93T31avq1kne7d4LO6eqvpHkz7r7BVPPAmtlmV+nbXlYXK9O8tGqunaS/xW/+e4KByS5emZ30lzpkPm6ZHZpcP8f7bw9k7x16iFgjS3t67SLRC2o7v5UZvvhX5vk9O7+8MQjLaM3J3l5Vf1qVR06f/vVJC/PbDNkktw+ySmTTbg8XpnZDchgaSzz67TfmBbbqzO7x8JTph5kSf1mZlfzPC6X/L/y/SSvyCU3IDs5s4tIsXP2S/Ib84PMPpEfPWDy8ZNMtUSq6qnbWNXd/cz5lTwPcnDqmlvK12nHPCywqrpKkscleWl3nzH1PMtqfnfH680//EJ3nzPlPMuoqv7lUlZ3d99t3YZZUlW1rUvXd3ffoqrek+S63X3Yes617Jb1dVo8AABDHPMAAAwRDwDAEPGwBKrqqKln2Ag8z+vHc70+PM/rZ9mea/GwHJbqL+VuzPO8fjzX68PzvH6W6rkWDwDAEGdbrLB37dP7Zv+pxxi2ORfkctln6jGWnud5/Szic33DW5w79QjDzvzmRbnqgXtOPcaQz3zlqlOPsEM2X3BOLrfPYv37cs63Tj+ru7f6hLtI1Ar7Zv/coZbm6qGQ7LFY/zAssne+86NTj7Ah3Pn3fnPqETaMD/3DE7+8rXV2WwAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQ8QDADBEPAAAQxYuHqrqX6vqxauWPbGqTq2qu1bV5qo6ZNX6Z1XVJ9Z3UgBYTgsXD5emu9+f5AtJHrJlWVXtMf/45VPNBQDLZKniYe5vkzx8xcf3THK1JMdt7cFVdVRVnVhVJ27OBesxHwAstEWNh6Oq6uwtb0metWLdq5IcVlV3nn/8iCRv6e5vbu0Ldfex3b2puzddLvvs4rEBYPEtajy8PsmtVrw9f8uK7j4zyVuTPKKqDkxyn9hlAQBrZq+pB9hB3+nuz2/5oKpWb1V4WZI3JvlikjOSvHsdZwOApbaoWx4uy7uSfDPJ05L8XXdfPPE8ALA0ljIeuruTvDLJ5eZ/AgBrZOF2W3T3EVtZdkySY1YtvnqS93T3qeswFgBsGAsXD5elqq6U5KaZXdvh1yYeBwCWztLFQ5Ljk9w+ycu7++1TDwMAy2bp4mFruzUAgLWzlAdMAgC7jngAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIaIBwBgiHgAAIbsNfUAu5O6/L7Z48Y3nXqMpXfx3ntOPcKGcd41Lj/1CBvG9d57i6lH2BAOO+OCqUcgtjwAAIPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwRDwAAEPEAwAwZOnioar+tapevOLjG1XV5qo6acq5AGBZLF08bMWfJzl/6iEAYFksdTxU1RFJ7pzkby/lMUdV1YlVdeKF3z933WYDgEW1tPFQVZXkeUmenuQ723pcdx/b3Zu6e9Pee+23bvMBwKJa2nhIcmSSA5K8ZOpBAGCZ7DX1ALvI5ZM8K8nju3vzbCMEALAWlnXLw68n+VJ3v2XqQQBg2SxrPOyX5PenHgIAltHSxUN3H9Hde3T3iSuWHd3dN59yLgBYFksXDwDAriUeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGCIeAIAh4gEAGLLX1APsVi64MPnCV6aeYuntcdFFU4+wYex/4aFTj7Bh3O66Z0w9woZw+lVvMPUIxJYHAGCQeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGDIDsdDVV1uLQcBABbDdsdDVR1WVX9TVZ+uqm8mOa+qbrQLZwMAdkPbFQ9VdZMkH02yV5JHJLlDkut192d34WwAwG5or+183IuT/HV3P2VXDgMA7P4uc8tDVe2f5KeT7F1Vn6uq86vqk1X1Syse8+yq+mxVnVdVp1bVc6tq3xXrj66qk6rqN6rqtPnj3lJVB636XodWVW/l7dAVjzmyqj5SVd+rqm9U1T9W1TVXrD9i/jkHzT++4vzxb66q7Y0lAGAbtme3xYFJKsmjkzwtyS2SvDnJm6rqVvPHnJPZ7oybJPmtJPdPsnorxaFJjkzyS0nukeQGSV6xje/5c0muPv9ztb3nc9wyyb2THJTkdVv7IlV1+SRvS/KtJPfv7u9f6k8KAFym7flNfEtgHNPdfz9//6lVddckT0xyZHc/c8XjT62qP52v+5MVyy+f5CHdfVqSVNWjk3ygqm7Q3Z+bP2af+Z9ndPcZVfXjq4fp7pXB8cWqekySk6vqx7v79BXr9k7ymiR7Jrlvd1+wtR+uqo5KclSS7Fv7X8rTAAAkY6dqnrDq4w8muWmSVNX9quqDVXVGVZ2d5AVJrr3q8V/dEg5zH0pycWZbK7Y4cP7nd7c1RFXdpqqOr6ovV9X3kpw4X7X6+706sy0XH+juc7f19br72O7e1N2b9r5kTwsAsA3bEw/fupR1XVV3TPIPSd6Z5BeT3DrJHyfZketAHJZkc5LTt7ZyfvzFO5Ocm+TBSW6XS3Zt7L3q4ddIct8kT6iqTTswCwCwFZcZD939nSRnJDl81aqfTPLp+fKvdvczu/sj810Q19nKl7pmVV1rxce3n3//k1cs+6kkH+ruzdsY58aZHePw5O5+f3d/JsnVtvHY+3b38UlelORVVbXPNh4HAAzY3t0WL0jyxKp6QFXdsKqekeQuSY5JckpmYfCg+YWkHpPkAVv5Gudl9o/4rarqTklekuTt3f25qtpzfgzFA5P8U1UdUlWH5JLdGFetqj2TnJbkgiSPnX+vX0jyzK18ryT5n/mffzz/OZ+xnT8rAHAptjcenpfkhZnFwkmZ7Q745e7+r+5+W5I/T/IXST6R5GeSPHUrX+PUzHZvvC3Je5N8McnD5+uuleR9SfbLLFS+Pn97x3z9h5Ncq7vPTPLQ+ff/dGZnXTzh0gbv7vPnn/O7810sAMBO2K7rHnT3RZmdOfEn21j/pCRPWrX4b7byuGOTHLuNb/Pl7j50ayuq6tQVX+P1SV6/+iEr1v/ryo/nyz6cS87kAAB2wu5yV82Lkpx5KevPnD8GAJjYbnHFxe7+SmZnTmxr/TbXAQDra122PHT30d198/X4XgDArrW77LYAABaEeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGDIXlMPsFvpTjZvnnqKpXfxhZ7j9bLn6f899QgbxinH3WjqETaEPqSmHoHY8gAADBIPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADBEPAMAQ8QAADNkQ8VBVJ1XV0VPPAQDLYEPEAwCwdsQDADBEPAAAQ/aaeoCpVdVRSY5Kkn1r/4mnAYDd34bf8tDdx3b3pu7etHf2mXocANjtbfh4AADGbIjdFt1986lnAIBlsSG2PFTVe6rqsVPPAQDLYEPEQ5LrJTlo6iEAYBlslN0Wh049AwAsi42y5QEAWCPiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCHiAQAYIh4AgCF7TT3A7qS7c/H55089BqyZi8765tQjbBhXe8XHph5hQ6iqqUfYMD5xKetseQAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhogHAGCIeAAAhixkPFTVE6vq1KnnAICNaCHjAQCYzprHQ1VdsaquvNZf9zK+51Wrat/1/J4AsFGtSTxU1Z5Vdc+q+vskZyS55Xz5larq2Kr6RlV9r6reV1WbVnzew6rq7Kq6e1WdVFXnVNW/VNV1V339P6yqM+aPfXWSA1aNcK8kZ8y/1+Fr8TMBAFu3U/FQVTerqucm+UqS1yc5J8nPJXl/VVWStye5ZpJ7J7l1kvcneW9VXX3Fl9knyZOSPCLJnZJcOclLVnyPX0vyf5I8Lcltknw2yRNWjfLaJA9McoUk76qqz1fVU1dHyDZ+hqOq6sSqOnFzLhh9CgBgw6nuHvuEqgOTPCjJQ5P8RJJ3JHlNkrd19/krHne3JG9NctXuPm/F8o8n+fvufm5VPSzJK5PcuLs/O1//oCSvSLJvd3dV/VuST3X3o1Z8jXcnuX53H7qV+a6Y5H5JHpzkLkk+mOTVSd7Q3Wdf2s92xbpK36HuPvR8ACRJ7bPP1CNsCLPfS1kP/3zecR/t7k1bW7cjWx4el+SFSc5PcsPuvk93/+PKcJi7bZL9kpw5391wdlWdneTmSa634nEXbAmHua8l2TvJj80/vkmSf1/1tVd//APd/d3ufkV3/3SS2yU5OMnLMwsKAGAn7bUDn3Nsks1JHpLkpKp6c2ZbHt7T3ReteNweSf47s9/+V/vuive/v2rdlk0hO7RLpar2yWw3yZGZHQvxqSS/m+T4Hfl6AMAPG/4Huru/1t3P6u4bJblHkrOT/EOS06vqeVV1q/lDP5bZb/0Xd/fnV719Y+BbnpzkjquW/dDHNfOTVfXSzA7YfFGSzye5bXffprtf2N3fGv1ZAYAftVMHTHb3f3T3Y5JcPbPdGTdM8pGqukuSdyc5IcnxVfXzVXXdqrpTVT19vn57vTDJQ6vqUVV1g6p6UpI7rHrMkUn+OckVkzwgybW6+w+6+6Sd+fkAgB+1I7stfkR3X5DkjUneWFVXS3LR/GDHe2V2psTLklwts90YJ2R2AOP2fu3XV9VhSZ6V2TEUb03y/CQPW/Gw9yQ5pLu/+6NfAQBYS8NnWywzZ1sAO8rZFuvD2RbrZ63PtgAANjDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwBDxAAAMEQ8AwJC9ph4AYBn0BRdMPcKG0FMPQBJbHgCAQeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAITEcMvcAAAH8SURBVOIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIeIBABgiHgCAIXtNPcDUquqoJEclyb7Zb+JpAGD3t+G3PHT3sd29qbs3XS77TD0OAOz2Nnw8AABjxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDxAMAMEQ8AABDqrunnmG3UVVnJvny1HPsgIOSnDX1EBuA53n9eK7Xh+d5/Szic32d7r7q1laIhyVQVSd296ap51h2nuf147leH57n9bNsz7XdFgDAEPEAAAwRD8vh2KkH2CA8z+vHc70+PM/rZ6mea8c8AABDbHkAAIaIBwBgiHgAAIaIBwBgiHgAAIb8f9PSjOLRnLCsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAai00DNYLek"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "  q, k, v must have matching leading dimensions.\n",
        "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "  The mask has different shapes depending on its type(padding or look ahead) \n",
        "  but it must be broadcastable for addition.\n",
        "  \n",
        "  Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable \n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    \n",
        "  Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxMmU_7rYLen"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, \n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "    \n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X91Zl3GkYLer"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "    \n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    \n",
        "    def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(\n",
        "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "    \n",
        "    \n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                                self.d_model)\n",
        "\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                           for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # adding embedding and position encoding.\n",
        "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE2AY_5fYLev"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                           for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                                 look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        # x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuTEjc-2YLe0"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                               input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                               target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TJMFAf8YLe5"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
        "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr3gs_8jYLfE"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5EPYo12YLfK"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "  \n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QGuXW-YYLfQ"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH_Yl6RPYLfT"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')\n",
        "\n",
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPojLYwzYLfX"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnfpCEDtYLfb"
      },
      "source": [
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "  \n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueeYooIWYLfg",
        "outputId": "f51492e0-7672-44d6-9817-627f89bf777e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)\n",
        "\n",
        "for epoch in range(100):\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        train_step(inp, tar)\n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 8.4160 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 8.2723 Accuracy 0.0117\n",
            "Epoch 1 Batch 100 Loss 8.0209 Accuracy 0.0507\n",
            "Epoch 1 Loss 7.9185 Accuracy 0.0584\n",
            "Epoch 2 Batch 0 Loss 7.4126 Accuracy 0.0909\n",
            "Epoch 2 Batch 50 Loss 7.2429 Accuracy 0.0909\n",
            "Epoch 2 Batch 100 Loss 7.0396 Accuracy 0.0938\n",
            "Epoch 2 Loss 6.9194 Accuracy 0.1063\n",
            "Epoch 3 Batch 0 Loss 6.1997 Accuracy 0.1619\n",
            "Epoch 3 Batch 50 Loss 5.9559 Accuracy 0.1654\n",
            "Epoch 3 Batch 100 Loss 5.6813 Accuracy 0.1733\n",
            "Epoch 3 Loss 5.5509 Accuracy 0.1766\n",
            "Epoch 4 Batch 0 Loss 4.8133 Accuracy 0.1918\n",
            "Epoch 4 Batch 50 Loss 4.6288 Accuracy 0.1937\n",
            "Epoch 4 Batch 100 Loss 4.4335 Accuracy 0.1980\n",
            "Epoch 4 Loss 4.3522 Accuracy 0.1995\n",
            "Epoch 5 Batch 0 Loss 3.8387 Accuracy 0.1960\n",
            "Epoch 5 Batch 50 Loss 3.7552 Accuracy 0.2119\n",
            "Epoch 5 Batch 100 Loss 3.6600 Accuracy 0.2146\n",
            "Epoch 5 Loss 3.6222 Accuracy 0.2163\n",
            "Epoch 6 Batch 0 Loss 3.2073 Accuracy 0.2372\n",
            "Epoch 6 Batch 50 Loss 3.2882 Accuracy 0.2283\n",
            "Epoch 6 Batch 100 Loss 3.2501 Accuracy 0.2294\n",
            "Epoch 6 Loss 3.2359 Accuracy 0.2297\n",
            "Epoch 7 Batch 0 Loss 3.1521 Accuracy 0.2287\n",
            "Epoch 7 Batch 50 Loss 3.0250 Accuracy 0.2337\n",
            "Epoch 7 Batch 100 Loss 2.9935 Accuracy 0.2350\n",
            "Epoch 7 Loss 2.9818 Accuracy 0.2354\n",
            "Epoch 8 Batch 0 Loss 2.8788 Accuracy 0.2429\n",
            "Epoch 8 Batch 50 Loss 2.8079 Accuracy 0.2399\n",
            "Epoch 8 Batch 100 Loss 2.8016 Accuracy 0.2405\n",
            "Epoch 8 Loss 2.7955 Accuracy 0.2405\n",
            "Epoch 9 Batch 0 Loss 2.7463 Accuracy 0.2386\n",
            "Epoch 9 Batch 50 Loss 2.6285 Accuracy 0.2448\n",
            "Epoch 9 Batch 100 Loss 2.6213 Accuracy 0.2459\n",
            "Epoch 9 Loss 2.6235 Accuracy 0.2460\n",
            "Epoch 10 Batch 0 Loss 2.4162 Accuracy 0.2599\n",
            "Epoch 10 Batch 50 Loss 2.4862 Accuracy 0.2503\n",
            "Epoch 10 Batch 100 Loss 2.4805 Accuracy 0.2505\n",
            "Epoch 10 Loss 2.4737 Accuracy 0.2507\n",
            "Epoch 11 Batch 0 Loss 2.3809 Accuracy 0.2443\n",
            "Epoch 11 Batch 50 Loss 2.3357 Accuracy 0.2539\n",
            "Epoch 11 Batch 100 Loss 2.3320 Accuracy 0.2551\n",
            "Epoch 11 Loss 2.3251 Accuracy 0.2553\n",
            "Epoch 12 Batch 0 Loss 2.2035 Accuracy 0.2656\n",
            "Epoch 12 Batch 50 Loss 2.1876 Accuracy 0.2595\n",
            "Epoch 12 Batch 100 Loss 2.1825 Accuracy 0.2591\n",
            "Epoch 12 Loss 2.1869 Accuracy 0.2592\n",
            "Epoch 13 Batch 0 Loss 1.9142 Accuracy 0.2599\n",
            "Epoch 13 Batch 50 Loss 2.0325 Accuracy 0.2636\n",
            "Epoch 13 Batch 100 Loss 2.0345 Accuracy 0.2643\n",
            "Epoch 13 Loss 2.0426 Accuracy 0.2645\n",
            "Epoch 14 Batch 0 Loss 2.0432 Accuracy 0.2628\n",
            "Epoch 14 Batch 50 Loss 1.9011 Accuracy 0.2678\n",
            "Epoch 14 Batch 100 Loss 1.9005 Accuracy 0.2703\n",
            "Epoch 14 Loss 1.9029 Accuracy 0.2702\n",
            "Epoch 15 Batch 0 Loss 1.9229 Accuracy 0.2827\n",
            "Epoch 15 Batch 50 Loss 1.7703 Accuracy 0.2750\n",
            "Epoch 15 Batch 100 Loss 1.7746 Accuracy 0.2757\n",
            "Epoch 15 Loss 1.7816 Accuracy 0.2752\n",
            "Epoch 16 Batch 0 Loss 1.6167 Accuracy 0.2741\n",
            "Epoch 16 Batch 50 Loss 1.6464 Accuracy 0.2809\n",
            "Epoch 16 Batch 100 Loss 1.6427 Accuracy 0.2808\n",
            "Epoch 16 Loss 1.6487 Accuracy 0.2811\n",
            "Epoch 17 Batch 0 Loss 1.6016 Accuracy 0.2756\n",
            "Epoch 17 Batch 50 Loss 1.4943 Accuracy 0.2879\n",
            "Epoch 17 Batch 100 Loss 1.5159 Accuracy 0.2863\n",
            "Epoch 17 Loss 1.5250 Accuracy 0.2862\n",
            "Epoch 18 Batch 0 Loss 1.4708 Accuracy 0.2884\n",
            "Epoch 18 Batch 50 Loss 1.3724 Accuracy 0.2924\n",
            "Epoch 18 Batch 100 Loss 1.3882 Accuracy 0.2927\n",
            "Epoch 18 Loss 1.3980 Accuracy 0.2920\n",
            "Epoch 19 Batch 0 Loss 1.1770 Accuracy 0.3139\n",
            "Epoch 19 Batch 50 Loss 1.2743 Accuracy 0.2985\n",
            "Epoch 19 Batch 100 Loss 1.2834 Accuracy 0.2974\n",
            "Epoch 19 Loss 1.2908 Accuracy 0.2970\n",
            "Epoch 20 Batch 0 Loss 1.1996 Accuracy 0.3040\n",
            "Epoch 20 Batch 50 Loss 1.1456 Accuracy 0.3056\n",
            "Epoch 20 Batch 100 Loss 1.1710 Accuracy 0.3031\n",
            "Epoch 20 Loss 1.1889 Accuracy 0.3023\n",
            "Epoch 21 Batch 0 Loss 0.9566 Accuracy 0.3224\n",
            "Epoch 21 Batch 50 Loss 1.0496 Accuracy 0.3120\n",
            "Epoch 21 Batch 100 Loss 1.0777 Accuracy 0.3094\n",
            "Epoch 21 Loss 1.0963 Accuracy 0.3080\n",
            "Epoch 22 Batch 0 Loss 1.1102 Accuracy 0.2969\n",
            "Epoch 22 Batch 50 Loss 0.9552 Accuracy 0.3160\n",
            "Epoch 22 Batch 100 Loss 0.9943 Accuracy 0.3110\n",
            "Epoch 22 Loss 1.0104 Accuracy 0.3103\n",
            "Epoch 23 Batch 0 Loss 0.8458 Accuracy 0.3224\n",
            "Epoch 23 Batch 50 Loss 0.8714 Accuracy 0.3206\n",
            "Epoch 23 Batch 100 Loss 0.9120 Accuracy 0.3168\n",
            "Epoch 23 Loss 0.9320 Accuracy 0.3148\n",
            "Epoch 24 Batch 0 Loss 0.8046 Accuracy 0.3253\n",
            "Epoch 24 Batch 50 Loss 0.8146 Accuracy 0.3244\n",
            "Epoch 24 Batch 100 Loss 0.8476 Accuracy 0.3197\n",
            "Epoch 24 Loss 0.8645 Accuracy 0.3187\n",
            "Epoch 25 Batch 0 Loss 0.6342 Accuracy 0.3438\n",
            "Epoch 25 Batch 50 Loss 0.7386 Accuracy 0.3285\n",
            "Epoch 25 Batch 100 Loss 0.7860 Accuracy 0.3238\n",
            "Epoch 25 Loss 0.8055 Accuracy 0.3220\n",
            "Epoch 26 Batch 0 Loss 0.7347 Accuracy 0.3253\n",
            "Epoch 26 Batch 50 Loss 0.7160 Accuracy 0.3305\n",
            "Epoch 26 Batch 100 Loss 0.7465 Accuracy 0.3269\n",
            "Epoch 26 Loss 0.7705 Accuracy 0.3241\n",
            "Epoch 27 Batch 0 Loss 0.6117 Accuracy 0.3565\n",
            "Epoch 27 Batch 50 Loss 0.6665 Accuracy 0.3351\n",
            "Epoch 27 Batch 100 Loss 0.7156 Accuracy 0.3281\n",
            "Epoch 27 Loss 0.7355 Accuracy 0.3265\n",
            "Epoch 28 Batch 0 Loss 0.6085 Accuracy 0.3523\n",
            "Epoch 28 Batch 50 Loss 0.6339 Accuracy 0.3372\n",
            "Epoch 28 Batch 100 Loss 0.6869 Accuracy 0.3310\n",
            "Epoch 28 Loss 0.7057 Accuracy 0.3287\n",
            "Epoch 29 Batch 0 Loss 0.5795 Accuracy 0.3466\n",
            "Epoch 29 Batch 50 Loss 0.6064 Accuracy 0.3379\n",
            "Epoch 29 Batch 100 Loss 0.6571 Accuracy 0.3326\n",
            "Epoch 29 Loss 0.6841 Accuracy 0.3300\n",
            "Epoch 30 Batch 0 Loss 0.6340 Accuracy 0.3565\n",
            "Epoch 30 Batch 50 Loss 0.5938 Accuracy 0.3401\n",
            "Epoch 30 Batch 100 Loss 0.6463 Accuracy 0.3340\n",
            "Epoch 30 Loss 0.6739 Accuracy 0.3310\n",
            "Epoch 31 Batch 0 Loss 0.5315 Accuracy 0.3523\n",
            "Epoch 31 Batch 50 Loss 0.5734 Accuracy 0.3416\n",
            "Epoch 31 Batch 100 Loss 0.6399 Accuracy 0.3341\n",
            "Epoch 31 Loss 0.6602 Accuracy 0.3321\n",
            "Epoch 32 Batch 0 Loss 0.5048 Accuracy 0.3551\n",
            "Epoch 32 Batch 50 Loss 0.5691 Accuracy 0.3419\n",
            "Epoch 32 Batch 100 Loss 0.6255 Accuracy 0.3348\n",
            "Epoch 32 Loss 0.6504 Accuracy 0.3328\n",
            "Epoch 33 Batch 0 Loss 0.5573 Accuracy 0.3253\n",
            "Epoch 33 Batch 50 Loss 0.5759 Accuracy 0.3401\n",
            "Epoch 33 Batch 100 Loss 0.6292 Accuracy 0.3360\n",
            "Epoch 33 Loss 0.6461 Accuracy 0.3339\n",
            "Epoch 34 Batch 0 Loss 0.4558 Accuracy 0.3722\n",
            "Epoch 34 Batch 50 Loss 0.5453 Accuracy 0.3424\n",
            "Epoch 34 Batch 100 Loss 0.6074 Accuracy 0.3366\n",
            "Epoch 34 Loss 0.6318 Accuracy 0.3341\n",
            "Epoch 35 Batch 0 Loss 0.4706 Accuracy 0.3494\n",
            "Epoch 35 Batch 50 Loss 0.5297 Accuracy 0.3438\n",
            "Epoch 35 Batch 100 Loss 0.5749 Accuracy 0.3400\n",
            "Epoch 35 Loss 0.5942 Accuracy 0.3378\n",
            "Epoch 36 Batch 0 Loss 0.4229 Accuracy 0.3551\n",
            "Epoch 36 Batch 50 Loss 0.5227 Accuracy 0.3435\n",
            "Epoch 36 Batch 100 Loss 0.5712 Accuracy 0.3398\n",
            "Epoch 36 Loss 0.5877 Accuracy 0.3382\n",
            "Epoch 37 Batch 0 Loss 0.5711 Accuracy 0.3452\n",
            "Epoch 37 Batch 50 Loss 0.4946 Accuracy 0.3467\n",
            "Epoch 37 Batch 100 Loss 0.5482 Accuracy 0.3420\n",
            "Epoch 37 Loss 0.5668 Accuracy 0.3404\n",
            "Epoch 38 Batch 0 Loss 0.5253 Accuracy 0.3565\n",
            "Epoch 38 Batch 50 Loss 0.5052 Accuracy 0.3463\n",
            "Epoch 38 Batch 100 Loss 0.5397 Accuracy 0.3427\n",
            "Epoch 38 Loss 0.5585 Accuracy 0.3414\n",
            "Epoch 39 Batch 0 Loss 0.4861 Accuracy 0.3693\n",
            "Epoch 39 Batch 50 Loss 0.4781 Accuracy 0.3485\n",
            "Epoch 39 Batch 100 Loss 0.5256 Accuracy 0.3441\n",
            "Epoch 39 Loss 0.5454 Accuracy 0.3420\n",
            "Epoch 40 Batch 0 Loss 0.3435 Accuracy 0.3608\n",
            "Epoch 40 Batch 50 Loss 0.4614 Accuracy 0.3502\n",
            "Epoch 40 Batch 100 Loss 0.5150 Accuracy 0.3451\n",
            "Epoch 40 Loss 0.5378 Accuracy 0.3424\n",
            "Epoch 41 Batch 0 Loss 0.4058 Accuracy 0.3565\n",
            "Epoch 41 Batch 50 Loss 0.4665 Accuracy 0.3488\n",
            "Epoch 41 Batch 100 Loss 0.5138 Accuracy 0.3454\n",
            "Epoch 41 Loss 0.5294 Accuracy 0.3437\n",
            "Epoch 42 Batch 0 Loss 0.3631 Accuracy 0.3494\n",
            "Epoch 42 Batch 50 Loss 0.4550 Accuracy 0.3505\n",
            "Epoch 42 Batch 100 Loss 0.5014 Accuracy 0.3462\n",
            "Epoch 42 Loss 0.5176 Accuracy 0.3443\n",
            "Epoch 43 Batch 0 Loss 0.3820 Accuracy 0.3608\n",
            "Epoch 43 Batch 50 Loss 0.4459 Accuracy 0.3526\n",
            "Epoch 43 Batch 100 Loss 0.4861 Accuracy 0.3485\n",
            "Epoch 43 Loss 0.5047 Accuracy 0.3461\n",
            "Epoch 44 Batch 0 Loss 0.2988 Accuracy 0.3807\n",
            "Epoch 44 Batch 50 Loss 0.4283 Accuracy 0.3553\n",
            "Epoch 44 Batch 100 Loss 0.4782 Accuracy 0.3499\n",
            "Epoch 44 Loss 0.4961 Accuracy 0.3473\n",
            "Epoch 45 Batch 0 Loss 0.3396 Accuracy 0.3622\n",
            "Epoch 45 Batch 50 Loss 0.4228 Accuracy 0.3544\n",
            "Epoch 45 Batch 100 Loss 0.4722 Accuracy 0.3492\n",
            "Epoch 45 Loss 0.4869 Accuracy 0.3476\n",
            "Epoch 46 Batch 0 Loss 0.3424 Accuracy 0.3821\n",
            "Epoch 46 Batch 50 Loss 0.4204 Accuracy 0.3549\n",
            "Epoch 46 Batch 100 Loss 0.4706 Accuracy 0.3490\n",
            "Epoch 46 Loss 0.4885 Accuracy 0.3473\n",
            "Epoch 47 Batch 0 Loss 0.4038 Accuracy 0.3651\n",
            "Epoch 47 Batch 50 Loss 0.4134 Accuracy 0.3552\n",
            "Epoch 47 Batch 100 Loss 0.4607 Accuracy 0.3498\n",
            "Epoch 47 Loss 0.4764 Accuracy 0.3481\n",
            "Epoch 48 Batch 0 Loss 0.4138 Accuracy 0.3310\n",
            "Epoch 48 Batch 50 Loss 0.4134 Accuracy 0.3547\n",
            "Epoch 48 Batch 100 Loss 0.4494 Accuracy 0.3505\n",
            "Epoch 48 Loss 0.4653 Accuracy 0.3490\n",
            "Epoch 49 Batch 0 Loss 0.3943 Accuracy 0.3665\n",
            "Epoch 49 Batch 50 Loss 0.4038 Accuracy 0.3537\n",
            "Epoch 49 Batch 100 Loss 0.4504 Accuracy 0.3511\n",
            "Epoch 49 Loss 0.4668 Accuracy 0.3494\n",
            "Epoch 50 Batch 0 Loss 0.3219 Accuracy 0.3935\n",
            "Epoch 50 Batch 50 Loss 0.3998 Accuracy 0.3561\n",
            "Epoch 50 Batch 100 Loss 0.4387 Accuracy 0.3514\n",
            "Epoch 50 Loss 0.4557 Accuracy 0.3503\n",
            "Epoch 51 Batch 0 Loss 0.2628 Accuracy 0.3778\n",
            "Epoch 51 Batch 50 Loss 0.3970 Accuracy 0.3559\n",
            "Epoch 51 Batch 100 Loss 0.4368 Accuracy 0.3516\n",
            "Epoch 51 Loss 0.4540 Accuracy 0.3500\n",
            "Epoch 52 Batch 0 Loss 0.3425 Accuracy 0.3494\n",
            "Epoch 52 Batch 50 Loss 0.3944 Accuracy 0.3568\n",
            "Epoch 52 Batch 100 Loss 0.4300 Accuracy 0.3520\n",
            "Epoch 52 Loss 0.4488 Accuracy 0.3508\n",
            "Epoch 53 Batch 0 Loss 0.2891 Accuracy 0.3807\n",
            "Epoch 53 Batch 50 Loss 0.3766 Accuracy 0.3550\n",
            "Epoch 53 Batch 100 Loss 0.4284 Accuracy 0.3513\n",
            "Epoch 53 Loss 0.4437 Accuracy 0.3503\n",
            "Epoch 54 Batch 0 Loss 0.3851 Accuracy 0.3580\n",
            "Epoch 54 Batch 50 Loss 0.3877 Accuracy 0.3558\n",
            "Epoch 54 Batch 100 Loss 0.4253 Accuracy 0.3528\n",
            "Epoch 54 Loss 0.4392 Accuracy 0.3516\n",
            "Epoch 55 Batch 0 Loss 0.3440 Accuracy 0.3665\n",
            "Epoch 55 Batch 50 Loss 0.3779 Accuracy 0.3585\n",
            "Epoch 55 Batch 100 Loss 0.4149 Accuracy 0.3541\n",
            "Epoch 55 Loss 0.4341 Accuracy 0.3515\n",
            "Epoch 56 Batch 0 Loss 0.3695 Accuracy 0.3622\n",
            "Epoch 56 Batch 50 Loss 0.3749 Accuracy 0.3559\n",
            "Epoch 56 Batch 100 Loss 0.4129 Accuracy 0.3529\n",
            "Epoch 56 Loss 0.4303 Accuracy 0.3515\n",
            "Epoch 57 Batch 0 Loss 0.3592 Accuracy 0.3793\n",
            "Epoch 57 Batch 50 Loss 0.3663 Accuracy 0.3610\n",
            "Epoch 57 Batch 100 Loss 0.4106 Accuracy 0.3537\n",
            "Epoch 57 Loss 0.4258 Accuracy 0.3525\n",
            "Epoch 58 Batch 0 Loss 0.3236 Accuracy 0.3693\n",
            "Epoch 58 Batch 50 Loss 0.3626 Accuracy 0.3603\n",
            "Epoch 58 Batch 100 Loss 0.4051 Accuracy 0.3549\n",
            "Epoch 58 Loss 0.4216 Accuracy 0.3529\n",
            "Epoch 59 Batch 0 Loss 0.3893 Accuracy 0.3466\n",
            "Epoch 59 Batch 50 Loss 0.3700 Accuracy 0.3583\n",
            "Epoch 59 Batch 100 Loss 0.4108 Accuracy 0.3535\n",
            "Epoch 59 Loss 0.4242 Accuracy 0.3518\n",
            "Epoch 60 Batch 0 Loss 0.3072 Accuracy 0.3693\n",
            "Epoch 60 Batch 50 Loss 0.3584 Accuracy 0.3585\n",
            "Epoch 60 Batch 100 Loss 0.3980 Accuracy 0.3552\n",
            "Epoch 60 Loss 0.4136 Accuracy 0.3534\n",
            "Epoch 61 Batch 0 Loss 0.2621 Accuracy 0.3849\n",
            "Epoch 61 Batch 50 Loss 0.3512 Accuracy 0.3611\n",
            "Epoch 61 Batch 100 Loss 0.3944 Accuracy 0.3551\n",
            "Epoch 61 Loss 0.4120 Accuracy 0.3532\n",
            "Epoch 62 Batch 0 Loss 0.2897 Accuracy 0.3622\n",
            "Epoch 62 Batch 50 Loss 0.3481 Accuracy 0.3587\n",
            "Epoch 62 Batch 100 Loss 0.3900 Accuracy 0.3547\n",
            "Epoch 62 Loss 0.4037 Accuracy 0.3537\n",
            "Epoch 63 Batch 0 Loss 0.3516 Accuracy 0.3679\n",
            "Epoch 63 Batch 50 Loss 0.3500 Accuracy 0.3591\n",
            "Epoch 63 Batch 100 Loss 0.3925 Accuracy 0.3548\n",
            "Epoch 63 Loss 0.4078 Accuracy 0.3536\n",
            "Epoch 64 Batch 0 Loss 0.3420 Accuracy 0.3707\n",
            "Epoch 64 Batch 50 Loss 0.3498 Accuracy 0.3614\n",
            "Epoch 64 Batch 100 Loss 0.3898 Accuracy 0.3560\n",
            "Epoch 64 Loss 0.4046 Accuracy 0.3545\n",
            "Epoch 65 Batch 0 Loss 0.2836 Accuracy 0.3494\n",
            "Epoch 65 Batch 50 Loss 0.3412 Accuracy 0.3592\n",
            "Epoch 65 Batch 100 Loss 0.3835 Accuracy 0.3554\n",
            "Epoch 65 Loss 0.4003 Accuracy 0.3537\n",
            "Epoch 66 Batch 0 Loss 0.2618 Accuracy 0.3594\n",
            "Epoch 66 Batch 50 Loss 0.3361 Accuracy 0.3615\n",
            "Epoch 66 Batch 100 Loss 0.3815 Accuracy 0.3561\n",
            "Epoch 66 Loss 0.3962 Accuracy 0.3541\n",
            "Epoch 67 Batch 0 Loss 0.3295 Accuracy 0.3509\n",
            "Epoch 67 Batch 50 Loss 0.3537 Accuracy 0.3586\n",
            "Epoch 67 Batch 100 Loss 0.3833 Accuracy 0.3563\n",
            "Epoch 67 Loss 0.3958 Accuracy 0.3544\n",
            "Epoch 68 Batch 0 Loss 0.2906 Accuracy 0.3679\n",
            "Epoch 68 Batch 50 Loss 0.3369 Accuracy 0.3614\n",
            "Epoch 68 Batch 100 Loss 0.3772 Accuracy 0.3559\n",
            "Epoch 68 Loss 0.3885 Accuracy 0.3549\n",
            "Epoch 69 Batch 0 Loss 0.3219 Accuracy 0.3778\n",
            "Epoch 69 Batch 50 Loss 0.3341 Accuracy 0.3612\n",
            "Epoch 69 Batch 100 Loss 0.3740 Accuracy 0.3571\n",
            "Epoch 69 Loss 0.3895 Accuracy 0.3552\n",
            "Epoch 70 Batch 0 Loss 0.3059 Accuracy 0.3565\n",
            "Epoch 70 Batch 50 Loss 0.3307 Accuracy 0.3613\n",
            "Epoch 70 Batch 100 Loss 0.3703 Accuracy 0.3570\n",
            "Epoch 70 Loss 0.3859 Accuracy 0.3553\n",
            "Epoch 71 Batch 0 Loss 0.3017 Accuracy 0.3778\n",
            "Epoch 71 Batch 50 Loss 0.3288 Accuracy 0.3614\n",
            "Epoch 71 Batch 100 Loss 0.3633 Accuracy 0.3568\n",
            "Epoch 71 Loss 0.3811 Accuracy 0.3549\n",
            "Epoch 72 Batch 0 Loss 0.2855 Accuracy 0.3651\n",
            "Epoch 72 Batch 50 Loss 0.3389 Accuracy 0.3591\n",
            "Epoch 72 Batch 100 Loss 0.3679 Accuracy 0.3572\n",
            "Epoch 72 Loss 0.3833 Accuracy 0.3548\n",
            "Epoch 73 Batch 0 Loss 0.3455 Accuracy 0.3636\n",
            "Epoch 73 Batch 50 Loss 0.3286 Accuracy 0.3614\n",
            "Epoch 73 Batch 100 Loss 0.3697 Accuracy 0.3564\n",
            "Epoch 73 Loss 0.3829 Accuracy 0.3557\n",
            "Epoch 74 Batch 0 Loss 0.2410 Accuracy 0.3707\n",
            "Epoch 74 Batch 50 Loss 0.3340 Accuracy 0.3601\n",
            "Epoch 74 Batch 100 Loss 0.3639 Accuracy 0.3571\n",
            "Epoch 74 Loss 0.3802 Accuracy 0.3555\n",
            "Epoch 75 Batch 0 Loss 0.3330 Accuracy 0.3622\n",
            "Epoch 75 Batch 50 Loss 0.3247 Accuracy 0.3609\n",
            "Epoch 75 Batch 100 Loss 0.3593 Accuracy 0.3572\n",
            "Epoch 75 Loss 0.3745 Accuracy 0.3557\n",
            "Epoch 76 Batch 0 Loss 0.3682 Accuracy 0.3523\n",
            "Epoch 76 Batch 50 Loss 0.3218 Accuracy 0.3627\n",
            "Epoch 76 Batch 100 Loss 0.3605 Accuracy 0.3576\n",
            "Epoch 76 Loss 0.3751 Accuracy 0.3558\n",
            "Epoch 77 Batch 0 Loss 0.3784 Accuracy 0.3466\n",
            "Epoch 77 Batch 50 Loss 0.3281 Accuracy 0.3613\n",
            "Epoch 77 Batch 100 Loss 0.3618 Accuracy 0.3577\n",
            "Epoch 77 Loss 0.3734 Accuracy 0.3555\n",
            "Epoch 78 Batch 0 Loss 0.2726 Accuracy 0.3920\n",
            "Epoch 78 Batch 50 Loss 0.3123 Accuracy 0.3645\n",
            "Epoch 78 Batch 100 Loss 0.3494 Accuracy 0.3585\n",
            "Epoch 78 Loss 0.3692 Accuracy 0.3565\n",
            "Epoch 79 Batch 0 Loss 0.3074 Accuracy 0.3778\n",
            "Epoch 79 Batch 50 Loss 0.3157 Accuracy 0.3624\n",
            "Epoch 79 Batch 100 Loss 0.3524 Accuracy 0.3573\n",
            "Epoch 79 Loss 0.3650 Accuracy 0.3558\n",
            "Epoch 80 Batch 0 Loss 0.3396 Accuracy 0.3565\n",
            "Epoch 80 Batch 50 Loss 0.3184 Accuracy 0.3618\n",
            "Epoch 80 Batch 100 Loss 0.3520 Accuracy 0.3580\n",
            "Epoch 80 Loss 0.3668 Accuracy 0.3563\n",
            "Epoch 81 Batch 0 Loss 0.2948 Accuracy 0.3580\n",
            "Epoch 81 Batch 50 Loss 0.3119 Accuracy 0.3639\n",
            "Epoch 81 Batch 100 Loss 0.3511 Accuracy 0.3585\n",
            "Epoch 81 Loss 0.3652 Accuracy 0.3569\n",
            "Epoch 82 Batch 0 Loss 0.3414 Accuracy 0.3381\n",
            "Epoch 82 Batch 50 Loss 0.3096 Accuracy 0.3612\n",
            "Epoch 82 Batch 100 Loss 0.3389 Accuracy 0.3590\n",
            "Epoch 82 Loss 0.3554 Accuracy 0.3576\n",
            "Epoch 83 Batch 0 Loss 0.2747 Accuracy 0.3622\n",
            "Epoch 83 Batch 50 Loss 0.3057 Accuracy 0.3642\n",
            "Epoch 83 Batch 100 Loss 0.3483 Accuracy 0.3585\n",
            "Epoch 83 Loss 0.3605 Accuracy 0.3574\n",
            "Epoch 84 Batch 0 Loss 0.2559 Accuracy 0.3608\n",
            "Epoch 84 Batch 50 Loss 0.3034 Accuracy 0.3656\n",
            "Epoch 84 Batch 100 Loss 0.3414 Accuracy 0.3591\n",
            "Epoch 84 Loss 0.3592 Accuracy 0.3573\n",
            "Epoch 85 Batch 0 Loss 0.2373 Accuracy 0.3665\n",
            "Epoch 85 Batch 50 Loss 0.3058 Accuracy 0.3639\n",
            "Epoch 85 Batch 100 Loss 0.3397 Accuracy 0.3591\n",
            "Epoch 85 Loss 0.3530 Accuracy 0.3577\n",
            "Epoch 86 Batch 0 Loss 0.3332 Accuracy 0.3494\n",
            "Epoch 86 Batch 50 Loss 0.3120 Accuracy 0.3606\n",
            "Epoch 86 Batch 100 Loss 0.3422 Accuracy 0.3574\n",
            "Epoch 86 Loss 0.3568 Accuracy 0.3560\n",
            "Epoch 87 Batch 0 Loss 0.2739 Accuracy 0.3523\n",
            "Epoch 87 Batch 50 Loss 0.3061 Accuracy 0.3635\n",
            "Epoch 87 Batch 100 Loss 0.3386 Accuracy 0.3598\n",
            "Epoch 87 Loss 0.3563 Accuracy 0.3569\n",
            "Epoch 88 Batch 0 Loss 0.2758 Accuracy 0.3679\n",
            "Epoch 88 Batch 50 Loss 0.3031 Accuracy 0.3644\n",
            "Epoch 88 Batch 100 Loss 0.3362 Accuracy 0.3597\n",
            "Epoch 88 Loss 0.3502 Accuracy 0.3575\n",
            "Epoch 89 Batch 0 Loss 0.3012 Accuracy 0.3551\n",
            "Epoch 89 Batch 50 Loss 0.3020 Accuracy 0.3645\n",
            "Epoch 89 Batch 100 Loss 0.3324 Accuracy 0.3606\n",
            "Epoch 89 Loss 0.3525 Accuracy 0.3578\n",
            "Epoch 90 Batch 0 Loss 0.3048 Accuracy 0.3665\n",
            "Epoch 90 Batch 50 Loss 0.3014 Accuracy 0.3641\n",
            "Epoch 90 Batch 100 Loss 0.3358 Accuracy 0.3590\n",
            "Epoch 90 Loss 0.3481 Accuracy 0.3574\n",
            "Epoch 91 Batch 0 Loss 0.2624 Accuracy 0.3722\n",
            "Epoch 91 Batch 50 Loss 0.2969 Accuracy 0.3623\n",
            "Epoch 91 Batch 100 Loss 0.3304 Accuracy 0.3595\n",
            "Epoch 91 Loss 0.3446 Accuracy 0.3576\n",
            "Epoch 92 Batch 0 Loss 0.2228 Accuracy 0.3821\n",
            "Epoch 92 Batch 50 Loss 0.3087 Accuracy 0.3629\n",
            "Epoch 92 Batch 100 Loss 0.3380 Accuracy 0.3587\n",
            "Epoch 92 Loss 0.3510 Accuracy 0.3571\n",
            "Epoch 93 Batch 0 Loss 0.3004 Accuracy 0.3764\n",
            "Epoch 93 Batch 50 Loss 0.3063 Accuracy 0.3615\n",
            "Epoch 93 Batch 100 Loss 0.3356 Accuracy 0.3586\n",
            "Epoch 93 Loss 0.3470 Accuracy 0.3574\n",
            "Epoch 94 Batch 0 Loss 0.3516 Accuracy 0.3281\n",
            "Epoch 94 Batch 50 Loss 0.2988 Accuracy 0.3624\n",
            "Epoch 94 Batch 100 Loss 0.3290 Accuracy 0.3587\n",
            "Epoch 94 Loss 0.3426 Accuracy 0.3574\n",
            "Epoch 95 Batch 0 Loss 0.2072 Accuracy 0.3793\n",
            "Epoch 95 Batch 50 Loss 0.2962 Accuracy 0.3636\n",
            "Epoch 95 Batch 100 Loss 0.3310 Accuracy 0.3588\n",
            "Epoch 95 Loss 0.3446 Accuracy 0.3572\n",
            "Epoch 96 Batch 0 Loss 0.2969 Accuracy 0.3793\n",
            "Epoch 96 Batch 50 Loss 0.2978 Accuracy 0.3630\n",
            "Epoch 96 Batch 100 Loss 0.3269 Accuracy 0.3594\n",
            "Epoch 96 Loss 0.3410 Accuracy 0.3576\n",
            "Epoch 97 Batch 0 Loss 0.2851 Accuracy 0.3551\n",
            "Epoch 97 Batch 50 Loss 0.3000 Accuracy 0.3626\n",
            "Epoch 97 Batch 100 Loss 0.3290 Accuracy 0.3585\n",
            "Epoch 97 Loss 0.3409 Accuracy 0.3570\n",
            "Epoch 98 Batch 0 Loss 0.2750 Accuracy 0.3736\n",
            "Epoch 98 Batch 50 Loss 0.2944 Accuracy 0.3627\n",
            "Epoch 98 Batch 100 Loss 0.3249 Accuracy 0.3589\n",
            "Epoch 98 Loss 0.3391 Accuracy 0.3570\n",
            "Epoch 99 Batch 0 Loss 0.2926 Accuracy 0.3509\n",
            "Epoch 99 Batch 50 Loss 0.2934 Accuracy 0.3614\n",
            "Epoch 99 Batch 100 Loss 0.3268 Accuracy 0.3580\n",
            "Epoch 99 Loss 0.3362 Accuracy 0.3576\n",
            "Epoch 100 Batch 0 Loss 0.2562 Accuracy 0.3580\n",
            "Epoch 100 Batch 50 Loss 0.2939 Accuracy 0.3624\n",
            "Epoch 100 Batch 100 Loss 0.3257 Accuracy 0.3588\n",
            "Epoch 100 Loss 0.3371 Accuracy 0.3572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6ncFZ0lYLfk",
        "outputId": "3a643718-b213-4f86-e00d-790ce679dbe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "    start_token = [1]\n",
        "    end_token = [2]\n",
        "  \n",
        "    sentence = preprocess_sentence(inp_sentence)\n",
        "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    \n",
        "    encoder_input = tf.expand_dims(inputs, 0)\n",
        "  \n",
        "  # as the target is english, the first word to the transformer should be the\n",
        "  # english start token.\n",
        "    decoder_input = [1]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(max_length_targ):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # select the last word from the seq_len dimension\n",
        "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "\n",
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "    fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "    sentence = inp_lang_tokenizer.encode(sentence)\n",
        "  \n",
        "    attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "    for head in range(attention.shape[0]):\n",
        "        ax = fig.add_subplot(2, 4, head+1)\n",
        "\n",
        "        # plot the attention weights\n",
        "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "        fontdict = {'fontsize': 10}\n",
        "\n",
        "        ax.set_xticks(range(len(sentence)+2))\n",
        "        ax.set_yticks(range(len(result)))\n",
        "\n",
        "        ax.set_ylim(len(result)-1.5, -0.5)\n",
        "\n",
        "        ax.set_xticklabels(\n",
        "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
        "            fontdict=fontdict, rotation=90)\n",
        "\n",
        "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                            if i < tokenizer_en.vocab_size], \n",
        "                           fontdict=fontdict)\n",
        "\n",
        "        ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def translate(sentence, plot=''):\n",
        "    result, attention_weights = evaluate(sentence)\n",
        "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
        "\n",
        "    print('Input: {}'.format(sentence))\n",
        "    print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "    if plot:\n",
        "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
        "        \n",
        "translate(\"good morning.\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: good morning.\n",
            "Predicted translation: ['<start>', 'с', 'добрым', 'утром', '!']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}